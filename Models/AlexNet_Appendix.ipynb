{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlexNet_Appendix.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"P_ifSkS2EBzn","colab_type":"text"},"cell_type":"markdown","source":["Here are some models I tried to run (many have these were tuned various different ways) before finding the model with the right hyperparameters providing the high accuracy metrics and minimal to no overfitting."]},{"metadata":{"id":"kChS96dmCCng","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0b6e6046-49f6-4175-fdf1-d9eae58863d8","executionInfo":{"status":"ok","timestamp":1556506859976,"user_tz":420,"elapsed":1609,"user":{"displayName":"Timothy Avila","photoUrl":"","userId":"02528264800099492283"}}},"cell_type":"code","source":["#For Google Collab\n","from google.colab import drive, auth\n","from googleapiclient.discovery import build\n","#For data manipulation\n","import numpy as np \n","import pandas as pd \n","import random\n","#For Plotting\n","import matplotlib.pyplot as plt\n","#For Modeling\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ReduceLROnPlateau\n","from keras import optimizers, regularizers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"G9DqTA-HCOuX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cb50f035-65ed-4223-c40b-522613904f6a","executionInfo":{"status":"ok","timestamp":1556506859987,"user_tz":420,"elapsed":1617,"user":{"displayName":"Timothy Avila","photoUrl":"","userId":"02528264800099492283"}}},"cell_type":"code","source":["# Load the Drive helper and mount\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"oR-Z4NBSCOry","colab_type":"code","colab":{}},"cell_type":"code","source":["auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jkV1v9Q-COpU","colab_type":"code","colab":{}},"cell_type":"code","source":["drive_service = build('drive', 'v3')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lb1bcA1ECOnB","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create variable for image and batch size along with number of epochs committing to for model\n","height = 224\n","width = 224\n","batch_size = 32\n","\n","train = ImageDataGenerator(rescale = 1/.255,rotation_range=30,horizontal_flip=True)\n","test = ImageDataGenerator(rescale=1/.255,rotation_range=30,horizontal_flip=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ll6hILE0COks","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"7027cba3-5bcc-4303-a5a6-2d2f1c7eedb5","executionInfo":{"status":"ok","timestamp":1556506863751,"user_tz":420,"elapsed":1000,"user":{"displayName":"Timothy Avila","photoUrl":"","userId":"02528264800099492283"}}},"cell_type":"code","source":["#Seting up train, test, and val sets for model\n","\n","train_set = train.flow_from_directory('../content/drive/My Drive/Chest_X_rays/All_Chest/train'\n","                                      ,target_size=(width,height), \n","                                      batch_size=batch_size,\n","                                      class_mode='categorical',\n","                                     seed = 122)\n","test_set = train.flow_from_directory('../content/drive/My Drive/Chest_X_rays/All_Chest/test'\n","                                      ,target_size=(width,height), \n","                                      batch_size=batch_size,\n","                                      class_mode='categorical',\n","                                    seed = 122)\n","val_set = train.flow_from_directory('../content/drive/My Drive/Chest_X_rays/All_Chest/val'\n","                                      ,target_size=(width,height), \n","                                      batch_size=batch_size,\n","                                      class_mode='categorical',                                   \n","                                    seed = 122)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Found 4747 images belonging to 3 classes.\n","Found 1885 images belonging to 3 classes.\n","Found 24 images belonging to 3 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"f-qvhSsvCOia","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"outputId":"a1633b1f-7ac7-40d4-967e-3d25d3862e57","executionInfo":{"status":"ok","timestamp":1556506870564,"user_tz":420,"elapsed":2019,"user":{"displayName":"Timothy Avila","photoUrl":"","userId":"02528264800099492283"}}},"cell_type":"code","source":["#Setting up model  94.13 %\n","#Model\n","model = Sequential()\n","\n","#Input layer 1\n","model.add(Conv2D(32,(3,3),input_shape=(height,width,3),activation='relu'))\n","model.add(Conv2D(32,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.1))\n","\n","#Hidden layer 2\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#Hidden layer 3\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.1))\n","\n","#Hidden layer 4\n","model.add(Conv2D(128,(3,3),activation='relu'))\n","model.add(Conv2D(128,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(1,1)))\n","\n","#Hidden layer 5\n","model.add(Conv2D(128,(3,3),activation='relu'))\n","model.add(Conv2D(128,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(1,1)))\n","\n","#Hidden layer 6\n","model.add(Conv2D(256,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","\n","#Output layer\n","model.add(Flatten())\n","model.add(Dense(units=128,activation='relu'))\n","model.add(Dropout(0.1))\n","model.add(Dense(units=3,activation='softmax'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"metadata":{"id":"TXmv-ZW6COgD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"49870491-6888-42ed-dd54-9d089990ece8"},"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","adam = optimizers.adam(lr=0.0001) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","rt=ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=1, verbose=1, mode='auto', min_delta=0.01, cooldown=1, min_lr=.00000000001)\n","\n","history = model.fit_generator(train_set, steps_per_epoch=25, epochs=epochs, validation_steps=50, verbose=1, validation_data=test_set, callbacks = [rt])\n","history"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/10\n","24/25 [===========================>..] - ETA: 12s - loss: 1.4339 - acc: 0.7070"],"name":"stdout"}]},{"metadata":{"id":"Zn1LbYyFCOdo","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history.history['loss'], label = 'Train')\n","plt.plot(history.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history.history['acc'], label = 'Train')\n","plt.plot(history.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BA_-KP5sCOa_","colab_type":"code","colab":{}},"cell_type":"code","source":["#Setting up model  94.13 % ---- Try decreasing the regulizer and dropout values\n","#Model\n","model = Sequential()\n","\n","#Input layer 1\n","model.add(Conv2D(128,(3,3),input_shape=(height,width,3),kernel_regularizer=regularizers.l2(0.3),activation='relu'))\n","model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","\n","#Hidden layer 2\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.6))\n","\n","#Hidden layer 3\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.7))\n","\n","#Hidden layer 4\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(1,1)))\n","model.add(Dropout(0.6))\n","\n","\n","#Hidden layer 5\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.5),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(1,1)))\n","model.add(Dropout(0.5))\n","\n","#Output layer\n","model.add(Flatten())\n","model.add(Dense(units=3,activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fg7U8T2wCOY2","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","adam = optimizers.adam(lr=0.001) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","rt=ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=1, verbose=1, mode='auto', min_delta=0.01, cooldown=1, min_lr=.00000000001)\n","\n","history = model.fit_generator(train_set, steps_per_epoch=5, epochs=epochs, validation_steps=50, verbose=1, validation_data=test_set, callbacks=[rt])\n","history"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gES0QjQeC0yd","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history.history['loss'], label = 'Train')\n","plt.plot(history.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history.history['acc'], label = 'Train')\n","plt.plot(history.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ac55MPTeC3Hg","colab_type":"code","colab":{}},"cell_type":"code","source":["#Setting up model  94.13 % ---- Try decreasing the regulizer and dropout values\n","#Model\n","model = Sequential()\n","\n","#Input layer 1\n","model.add(Conv2D(64,(3,3),input_shape=(height,width,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.4))\n","\n","#Hidden layer 2\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.3))\n","\n","\n","#Hidden layer 4\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","\n","\n","#Hidden layer 5\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.2),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.4))\n","\n","\n","#Output layer\n","model.add(Flatten())\n","model.add(Dropout(0.4))\n","model.add(Dense(units=3,activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mLiHI6epC3Fa","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","adam = optimizers.adam(lr=0.1) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","rt=ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.01, cooldown=1, min_lr=.00000001)\n","\n","history = model.fit_generator(train_set, steps_per_epoch=5, epochs=epochs, validation_steps=50, verbose=1, validation_data=test_set, callbacks=[rt])\n","history"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ebnTU24pC3DH","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history.history['loss'], label = 'Train')\n","plt.plot(history.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history.history['acc'], label = 'Train')\n","plt.plot(history.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nTQdodm-C3A_","colab_type":"code","colab":{}},"cell_type":"code","source":["#Setting up model  increasing and adding dropouts to help regularization\n","#Model\n","model = Sequential()\n","\n","#Input layer 1\n","model.add(Conv2D(128,(3,3),input_shape=(height,width,3),activation='relu'))\n","model.add(Conv2D(28,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 2\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 3\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(Conv2D(64,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 4\n","model.add(Conv2D(32,(3,3),activation='relu'))\n","model.add(Conv2D(32,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 5\n","model.add(Conv2D(32,(3,3),activation='relu'))\n","model.add(Conv2D(32,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(1,1)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 6\n","model.add(Conv2D(16,(3,3),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.2))\n","\n","#Output layer\n","model.add(Flatten())\n","model.add(Dense(units=32,activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=3,activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ap2XBykMC2-o","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","adam = optimizers.adam(lr=0.00000001) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history_test2 = model.fit_generator(train_set, steps_per_epoch=25, epochs=epochs, validation_steps=50, verbose=1, validation_data=test_set)\n","history_test2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M6rvaWpFC28Q","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history_test2.history['loss'], label = 'Train')\n","plt.plot(history_test2.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history_test2.history['acc'], label = 'Train')\n","plt.plot(history_test2.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xtcZoWJtC25p","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","adam = optimizers.adam(lr=0.1) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","rt=ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.01, cooldown=1, min_lr=.00000001)\n","\n","history = model.fit_generator(train_set, steps_per_epoch=5, epochs=epochs, validation_steps=10, verbose=1, validation_data=test_set, callbacks=[rt])\n","history"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c6YaPjQQDC0v","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history_test2.history['loss'], label = 'Train')\n","plt.plot(history_test2.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history_test2.history['acc'], label = 'Train')\n","plt.plot(history_test2.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mUQ3SACYDCyr","colab_type":"code","colab":{}},"cell_type":"code","source":["#Setting up model  adding regularization\n","#Model\n","model = Sequential()\n","​\n","#Input layer 1\n","model.add(Conv2D(256,(3,3),input_shape=(height,width,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(Conv2D(256,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","​\n","#Hidden layer 2\n","model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","​\n","#Hidden layer 3\n","model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(Conv2D(128,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","​\n","#Hidden layer 4\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","​\n","#Hidden layer 5\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(1,1)))\n","model.add(Dropout(0.2))\n","​\n","#Hidden layer 6\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.2))\n","​\n","#Output layer\n","model.add(Flatten())\n","model.add(Dropout(0.2))\n","model.add(Dense(units=3,activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UnqyoT31DCwj","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 32\n","epochs = 10\n","\n","adam = optimizers.adam(lr=0.1) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","rt=ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.01, cooldown=1, min_lr=.00000001)\n","\n","history = model.fit_generator(train_set, steps_per_epoch=5, epochs=epochs, validation_steps=10, verbose=1, validation_data=test_set, callbacks=[rt])\n","history"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c_UiFWggDCuO","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history.history['loss'], label = 'Train')\n","plt.plot(history.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history.history['acc'], label = 'Train')\n","plt.plot(history.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rO9SqpKZDCr7","colab_type":"code","colab":{}},"cell_type":"code","source":["#Setting up model  adding regularization\n","#Model\n","model = Sequential()\n","\n","#Input layer 1\n","model.add(Conv2D(128,(3,3),input_shape=(height,width,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","#model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 2\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","#model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 3\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","#model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 4\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","#model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 5\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","#model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n","#Hidden layer 6\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.2))\n","\n","#Output layer\n","model.add(Flatten())\n","model.add(Dense(units=32,kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units=3,activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0U9nfJdDDCpg","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 64\n","epochs = 10\n","\n","adam = optimizers.adam(lr=0.1) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","rt=ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.01, cooldown=1, min_lr=.00000001)\n","\n","history = model.fit_generator(train_set, steps_per_epoch=5, epochs=epochs, validation_steps=5, verbose=1, validation_data=test_set, callbacks=[rt])\n","history"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iOWjOY5-DNsW","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history.history['loss'], label = 'Train')\n","plt.plot(history.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history.history['acc'], label = 'Train')\n","plt.plot(history.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Hsr8ImT0DPtx","colab_type":"code","colab":{}},"cell_type":"code","source":["#Setting up model  adding regularization\n","#Model\n","model = Sequential()\n","\n","#Input layer 1\n","model.add(Conv2D(128,(3,3),input_shape=(height,width,3),kernel_regularizer=regularizers.l2(0.1),activation='relu'))\n","#model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","\n","#Hidden layer 2\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.1),activation='relu'))\n","#model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","\n","#Hidden layer 3\n","model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.1),activation='relu'))\n","#model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","\n","#Hidden layer 4\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.1),activation='relu'))\n","#model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","\n","#Hidden layer 5\n","model.add(Conv2D(32,(3,3),kernel_regularizer=regularizers.l2(0.1),activation='relu'))\n","#model.add(Conv2D(64,(3,3),kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.5))\n","\n","#Output layer\n","model.add(Flatten())\n","model.add(Dense(units=3,activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HCDZpiDLDSJw","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 16\n","epochs = 5\n","\n","adam = optimizers.adam(lr=0.0001) #, decay=1e-6, momentum=0.9, nesterov=True\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history_test5 = model.fit_generator(train_set, steps_per_epoch=5, epochs=epochs, validation_steps=5, verbose=1, validation_data=test_set)\n","history_test5"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W0jUr4K-DSH_","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(history_test5.history['loss'], label = 'Train')\n","plt.plot(history_test5.history['val_loss'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.title('Loss')\n","plt.show()\n","\n","plt.plot(history_test5.history['acc'], label = 'Train')\n","plt.plot(history_test5.history['val_acc'], label = 'Test')\n","plt.legend(loc = 'upper right')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.title('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LCiF78zTDSE5","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"zGyarli-DSCm","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"FdTwes3JDSAb","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"wcoflAcJDR-A","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"B75hTROlDR7u","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q6OWkatPDR5Q","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"yvALWDn9DR2p","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}